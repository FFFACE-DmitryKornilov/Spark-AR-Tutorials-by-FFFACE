Randomizer filters are some of the simplest and most common Instagram effects. At the same time, it can be complicated with additional effects for the face, backgrounds and 3D objects, based on the same mechanics of randomly changing options.\par
\par
In addition to this, the basic randomizer filter is a great example for getting familiar with spark AR interfaces and its node system - the patch editor.\par
\par
Now, we will put together a chain of patches step by step with the help of how the randomizer mechanics are implemented. Then, we will add objects on which it will be played. At the end you will have a filter ready for uploading.\par
\par
1. First, click the right mouse button (further in the text RMB) on the \b\f1 scene\b0\f0  tab at the top left, and choose \b\f1 add>facemesh\b0\f0 . This will automatically add a \b\f1 Facetracker \b0\f0 object to the scene. The \b\f1 facemesh\b0\f0  will be under the facetracker, with a slight shift to the right. This means that facemesh is a child object and the facetracker is a parent object. If we move, hide, or change the layer for the parent object, the same happens with its child objects. And to the left of the facetracker there will be an arrow, which if you click, you can collapse / expand all objects that belong to it.\par
\par
By the same principle, for example, if we add a rectangle to the scene, the canvas will be automatically created as its parent object.\par
\par
2. In our case, we won\rquote t use the facemesh, but we need a facetracker to track the position of the face. We remove the facemesh and then click RMB on the facetracker and click \b\f1 add>plane\b0\f0 . The plane is now a child object of facetracker, and therefore moves and rotates with the face on the screen.\par
\par
3. Now the plane is in the middle of the face, in order to move it, for example, on the forehead, you can \b\f1 pause\b0\f0  the filter playback, and then use the arrows in the 3D viewport to move the plane up.\par
\par
4. There is another, more flexible way to make the plane move with the face. This time using the \b\f1 patch editor\b0\f0 . To do this, you can add a plane by clicking RMB this time on the \b\f1 Camera \b0\f0 object in the scene tab. In the 3D viewport we will see a stationary plane appear in the scene, at the point from where the camera is looking.\par
\par
5. Now select the plane, and on the right side, under the \b\f1 Transformations\b0\f0  section, click on the arrow icon to the left of \b\f1 position \b0\f0 values. This will automatically open the patch editor under the 3D view and a yellow patch will appear there; now it controls the position of the plane. \b\f1 Yellow\b0\f0  means the patch is receiving information. The yellow arrow near the \b\f1 position\b0\f0  value on the right in the transformations section will now be highlighted, and editing from there will be blocked. This means that it is now only adjustable with patches.\par
\par
6. Click RMB on the \b\f1 facetracker\b0\f0  in the \b\f1 scene tab\b0\f0  and pick \b\f1 create patch\b0\f0 . This will create a ready-made bundle of patches, on the right end of which there will be four outputs with different information: \b\f1 Face, 3D position, 3D scale, 3D rotation\b0\f0 . We need to click on the arrow with \ldblquote 3D\rdblquote  and drag it to the arrow on the yellow patch that controls the position of the plane. Now we will see that the plane moves with the face, but at the same time it doesn't rotate, it remains perpendicular to the direction of view, since we only connected the position, but not the rotation.\par
\par
7. Now the plane is again in the middle of the face, but we can no longer move it with the help of the manipulator arrows in the viewport, since its position is controlled by patches. To move the plane up with patches, we click RMB on an empty field in the patch editor, and pick \b\f2\lang1049\'c0\f1\lang9 dd\b0\f0  patch to add some value to the height.\par
\par
8. It is important here that \b\f1 position\b0\f0  includes three different values, for three axes in space, and so that the \b\f1 Add\b0\f0  patch can process them separately, you need to change the type of data that it transfers. To do this, click on it, and a blue drop-down menu appears below. There you need to select \b\f1 vector 3\b0\f0 . Now we connect the \b\f1 3D position\b0\f0  output from facetracker to the \b\f1 Add\b0\f0  patch, and the \b\f1 Add\b0\f0  patch output to the yellow \b\f1 position\b0\f0  patch of the plane. Now if we change the values in the second line of the add patch, these values will be added to the position value along the corresponding axes.\par
\par
9. Enter 0.1 in the Y value window, to move the plane up by 0.1\par
\par
10. To place questions and answers for a randomizer on the plane, you need to create a material. To do this, select the plane on the left in the scene tab, and then click the plus icon on the right of the material section. This will create the material and it will also appear in the \b\f1 asset\b0\f0  window at the bottom left.\par
\par
11. Now select the material in\b\f1  assets\b0\f0 , and its parameters will appear on the right. There we change the \b\f1 shader type\b0\f0  to \b\f1 flat\b0\f0 . The flat material does not react to light sources, and there will be no shadows or highlights. With this material, the image used as a texture will show no color distortion. In this case, the color of the material should be pure white, otherwise it will mix with the texture and affect it.\par
\par
12. Now upload the texture of the image that we will use at the beginning of the effect, there will be a question on it. To do this, click on the \b\f1 add asset \b0\f0 at the bottom of the \b\f1 assets\b0\f0  window, and select \b\f1 import from computer\b0\f0 . The texture will also appear in assets. Click on it and in its parameters on the right, check the \b\f1 no compression\b0\f0  box. this will speed up the application and allow the effect to load faster. You should keep in mind that all files used in the project should in total be no more than 4MB (for instagram) and 10MB (for facebook). It is necessary to reduce the textures in advance and optimize the models to the minimum acceptable size and quality in the appropriate software.\par
\par
13. Now let's load the images that will be used as answers. We'll work with them as a sequence of frames, so we'll load them in a different way. We press \b\f1 add asset\b0\f0  again, but now select \b\f1 add animation sequence\b0\f0 . And already in its settings on the right, we add our textures, all at once. They will appear in one line in \b\f1 assets\b0\f0 . You need to select them, and check the \b\f1 no compression\b0\f0  checkbox in the settings on the right.\par
\par
14. Now let's add textures to our material using the patch editor. To do this, drag them from the \b\f1 assets\b0\f0  to the patch editor space. We drag the question texture from the textures folder in assets. But in the case of the answer textures sequence, you don\rquote t drag the texture icon from the \b\f1 textures\b0\f0 , but the \b\f1 animation sequence\b0\f0  icon. Now in the material settings, click on the arrow icon near the \b\f1 texture \b0\f0 slot. This will create a patch for it. If we connect the output of  the orange texture patch to the yellow patch input, we will see an image appear in our plane on the screen.\par
\par
15. However, we will need the question to be replaced by answers - so that a while after the start of recording the video, the texture of the question is replaced by the textures of the answer options. We will program it like this: add the \b\f1 if then else\b0\f0  patch, and add the \b\f1 camera\b0\f0  patch (to do this, you can simply drag the \b\f1 camera\b0\f0  to the patch editor from the scene tab). Connect the \b\f1 video recording\b0\f0  output from \b\f1 camera \b0\f0 patch to the \b\f1 condition\b0\f0  input of the \b\f1 if then else\b0\f0  patch. Connect textures of answers to \b\f1 then\b0\f0  input, and texture of question to the \b\f1 else\b0\f0  input.\par
\par
16. To test how it works \b\f1 interactively\b0\f0  in Spark AR, temporarily replace the \b\f1 camera\b0\f0  patch with the \b\f1 value\b0\f0  patch, and set its type to \b\f1 boolean\b0\f0 . Now by checking the box in the value, we simulate the start of video recording signal.\par
\par
17. Now, if you now check the box in the \b\f1 value \b0\f0 patch, the picture with the question will be changed to an animation from pictures with answers. But we don\rquote t wan\rquote t this to happen immediately, but a few seconds after starting to record. To do this, we will add a \b\f1 delay\b0\f0  patch and insert it between \b\f1 value\b0\f0  and the \b\f1 if then else \b0\f0 patches. Set the delay value to 2 (seconds).\par
.\par
18. Now let's set up the animation to change the answer options. Now they are controlled by the settings, which we can see on the right by clicking on the animation sequence in the \b\f1 assets\b0\f0 . Here in the settings, we can specify that the animation is looped, plays frames in random order, and the frame rate per second. However, we can\rquote t stop the animation from using patches. The only variable we can control with patches is the \b\f1 current frame\b0\f0 .\par
\par
19. If we click on the arrow near the\b\f1  current frame\b0\f0 , we will be able to control it with patches, while the settings in the column on the right will no longer be relevant. Now let's reproduce the animation we need using patches. To do this, we need the\b\f1  loop animation\b0\f0  and \b\f1 random\b0\f0  patches. The loop animation has two outputs, this is the progress of animation, and a signal that fires every time the animation ends. We will use the latter. Set the animation duration to 0.05 seconds. Now connect the\b\f1  looped\b0\f0  output to \b\f1 randomize\b0\f0  the input of \b\f1 random\b0\f0  patch. Now, every time the animation ends (every 0.05 seconds), a signal will be sent to a \b\f1 random\b0\f0  patch, and a random value from 0 to 20 will be generated there (we specify 20 because we have 20 frames in our sequence, this can be seen in the \b\f1 assets,\b0\f0  in the texture folder)\par
\par
20. Now we need to stop the animation after a while. To do this, we will use the delay patch again, like in the case of changing the texture of the question to the texture of answers, but this time we will set the delay to a larger value - 6 seconds. In addition, after the \b\f1 delay\b0\f0  patch, we add a \b\f1 not\b0\f0  patch, so when the video recording turns on, the animation will turn off (with a 6 second delay).\par
\par
21. Remember to connect the output \b\f1 video recording\b0\f0  to the \b\f1 value\b0\f0  patch that controls our mechanics. Now the whole chain looks like this - the user starts recording a video, after two seconds the picture with the question is replaced by an animation of randomly changing answers, and after 4 seconds, this animation stops at a randomly selected option. Now, the filter is ready. You can send a test link to the device, and if everything is ok, export the file for upload.\par
\par
}
�
